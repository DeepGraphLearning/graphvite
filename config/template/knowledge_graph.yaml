###########################################################
# Knowledge graph embedding configuration file
###########################################################

application:
  knowledge graph

resource:
  # List of GPU ids. Default is all GPUs
  gpus: []
  # Memory limit for each GPU in bytes. Default is all available memory.
  gpu_memory_limit: auto
  # Number of CPU thread per GPU. Default is all CPUs.
  cpu_per_gpu: auto
  # Dimension of the embeddings.
  dim: 1024

format:
  # String of delimiter characters. Change it if your node name contains blank character.
  delimiters: " \t\r\n"
  # Prefix of comment strings. Change it if you use comment style other than Python.
  comment: "#"

graph:
  # Path to triplet file. Each line should be one of the following
  # [head] [delimiter] [relation] [tail] [comment]...
  # [head] [delimiter] [relation] [tail] [delimiter] [weight] [comment]...
  # [comment]...
  # For standard datasets, you can specify them by <[dataset].[split]>.
  file_name:
  # Normalize the adjacency matrix or not. This may influence the performance a little.
  normalization: false

build:
  optimizer:
    # Optimizer.
    type: Adam
    # Learning rate. Default is usually reasonable.
    lr: 5.0e-5
    # Weight decay.
    weight_decay: 0
    # Learning rate schedule, can be "linear" or "constant". Linear is recommended.
    schedule: linear
  # Number of partitions. Auto is recommended.
  num_partition: auto
  # Number of negative samples per positive sample.
  # Larger value results in slower training.
  num_negative: 64
  # Batch size of samples in CPU-GPU transfer. Default is recommended.
  batch_size: 100000
  # Number of batches in a partition block.
  # Default is recommended.
  episode_size: auto

train:
  # Model, can be TransE, DistMult, ComplEx, SimplE or RotatE
  model: TransE
  # Number of epochs. Default is usually reasonable.
  num_epoch: 2000
  # L3 regularization (DistMult, ComplEx and SimplE). Need to be tuned on the validation set.
  l3_regularization: 2.0e-3
  # Margin (TransE, RotatE). Need to be tuned on the validation set.
  margin: 12
  # Batch size of samples in samplers. Default is recommended.
  sample_batch_size: 2000
  # Temperature for self-adversarial negative sampling. Default is usually reasonable.
  adversarial_temperature: 2
  # Log every n batches.
  log_frequency: 100

# Comment out this section if not needed.
evaluate:
  # Comment out any task if not needed.
  - task: link prediction
    # Path to triplet file. Each line should be one of the following
    # [head] [delimiter] [relation] [tail] [comment]...
    # [head] [delimiter] [relation] [tail] [delimiter] [weight] [comment]...
    # [comment]...
    file_name:
    # List of paths to filter files.
    # Specify all dataset splits for filtered ranking. Comment out for unfiltered ranking.
    filter_files:
    # Target entity to rank, can be head, tail or both.
    target: both
    # Number of samples to be evaluated. Comment out for precise evaluation.
    # fast_mode: 3000
    # Backend, can be graphvite or torch
    backend: graphvite

  - task: entity prediction
    # Path to triplet file. Each line should be one of the following
    # [head] [delimiter] [relation] [tail] [comment]...
    # [head] [delimiter] [relation] [tail] [delimiter] [weight] [comment]...
    # [comment]...
    file_name:
    # Path to save file, can be "*.txt" or "*.pkl".
    save_file:
    # Target entity to predict, can be head or tail.
    target: tail
    # Top-k recalls will be returned.
    k: 10
    # Backend, can be graphvite or torch.
    backend: graphvite

# Comment out this section if not needed.
save:
  file_name: knowledge_graph.pkl